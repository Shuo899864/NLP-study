# 模型
## 检索模型
给定一段对话历史，检索模型可以给候选回答打分并选出分数最高的一句回复。这里使用poly-encoder结构，先对上下文进行编码，再对候选回答编码，然后一起做注意力，计算分数。
## 生成模型
使用标准transformer模型，但是这里encoder的层数比较少，decoder的层数比较多。
## 检索提炼模型
使用生成模型可能会生成一些不可控的回复，并且不能融合外部知识。因此在生成前进行一次检索，包含两个检索步骤：对话检索和知识检索.
### 对话检索
先使用前面的检索模型检索出一句回复，然后这句话放在生成模型的输入后面，生成模型要做的就是学会恰当地提取这句话中的信息。
### 知识检索
与对话检索的机制一样，在知识库中进行检索。此外还训练了一个基于transformer的分类器来区分什么时候要使用知识，什么时候不用。
# 训练目标
## 检索排序loss
1个正确回复的分数和n-1个错误回复的分数放在一起计算交叉熵损失。这样做可以重复利用每个回复的embedding，达到加速效果。
## 生成loss
LMLE(pθ, x, y) = −sum(log pθ(yt|x, y<t))也就是给定上文，最大化每个正确token生成的概率。
## 检索提炼loss
前面两种loss效果不好，因为正确回复和检索回复之间的关系不明确，因此模型倾向于忽略检索回复。为了解决这个问题，检索回复有a%的几率被替换成正确回复，相当于检索和生成做了一个折中。对于知识检索，这种问题不存在，因为知识和回复之间有确定的关系，因此训练只是用知识检索。
## 生成任务的非似然训练
LUL(pθ, C, x, y) = −sum(sum(log(1-pθ(yc|x, y<t))))也就是在每个时间步，只有在选定的词典C中的yc才会被计算loss，最后LULE=LMLE+aLUL，可以缓解过度呈现词汇的问题，词典C中的词如果多次出现会增大loss。MLE用来提高正确token出现的概率，而UL用来降低错误token出现的概率。C的生成一般是统计生成过程中n-gram范围的词语分布，如果词语的出现频次超出正确回复中该词语的分布，就加入C中。
# 解码
## 束搜索
贪婪搜索每次选择概率最大的token，束搜索每次挑选概率最大的几个值，将它们放在已生成序列后面，然后对结果评分，选择分数最大的。
## 采样
防止采样到低概率的token，每次只在词典的一个子集里采样。采样方法有选取top-k，或者采样S次选取概率最高的。
## 回复的长度
束搜索可能会生成比较短的回复，可能会显得没有吸引力，长回复可以提供更多信息，显得不那么笨。控制回复长度有两种方法：一种是设置一个回复的最小长度，低于这个长度不产生句子结尾标记；第二种是先用一个分类器预测回复长度可能的区间，然后使用预测的长度去限制模型。
## 子序列阻塞
生成的时候有可能会重复某些片段，因此如果重复生成一个n-gram（这里n=3）会阻塞生成并把任意一个对话者的上一句重新输入。
# 训练细节
## 排序模型
使用MLM训练，超参数与roberta相同。
## 生成模型
使用adam优化器和megatron-LM模型，后者可以减少并行训练GPU的通信开销。训练使用了混合精度，梯度和优化器状态使用FP32，模型参数使用FP16。在微调阶段使用了GPipe-style模型并行，所有层的参数在不同GPU上共享，并且每个batch被切成更小的batch。
